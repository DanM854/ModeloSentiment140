{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96bb2aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import pickle\n",
    "import itertools\n",
    "import random\n",
    "from typing import Callable, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy.lang.en.stop_words import STOP_WORDS as SPACY_STOPWORDS\n",
    "\n",
    "import emoji\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import mlflow\n",
    "import mlflow.sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5aadeaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "random.seed(SEED); np.random.seed(SEED)\n",
    "\n",
    "MLFLOW_URI = \"file:./mlruns\"\n",
    "EXPERIMENT_NAME = \"sentiment140_ablation_preproc\"\n",
    "mlflow.set_tracking_uri(MLFLOW_URI)\n",
    "mlflow.set_experiment(EXPERIMENT_NAME)\n",
    "\n",
    "# SpaCy model (English)\n",
    "SPACY_MODEL = \"en_core_web_lg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc3dca89",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL_RE = re.compile(r\"(https?://\\S+|www\\.\\S+)\")\n",
    "MENTION_RE = re.compile(r\"@\\w+\")\n",
    "HASHTAG_RE = re.compile(r\"#\")\n",
    "MULTI_SPACE_RE = re.compile(r\"\\s+\")\n",
    "PUNCT_RE = re.compile(r\"[^\\w\\s]\")  # opción simple para quitar puntuación\n",
    "\n",
    "def normalize_elongation_token(token: str) -> str:\n",
    "    # Reduce repeticiones >2 a 2 (goooood -> good)\n",
    "    return re.sub(r'(.)\\1{2,}', r'\\1\\1', token)\n",
    "\n",
    "def demojize_text(text: str) -> str:\n",
    "    # convertir emojis a texto :smile:\n",
    "    return emoji.demojize(text, delimiters=(\" \", \" \"))\n",
    "\n",
    "def remove_emojis(text: str) -> str:\n",
    "    return emoji.replace_emoji(text, replace=\" \")\n",
    "\n",
    "# Factory: devuelve función preprocess(text)\n",
    "def preprocess_factory(\n",
    "    nlp: Optional[English],\n",
    "    lemmatize: bool = False,\n",
    "    drop_stopwords: bool = False,\n",
    "    handle_emojis: str = \"keep\",  # \"keep\" | \"demojize\" | \"remove\"\n",
    "    drop_punct: bool = False,\n",
    "    normalize_elong: bool = False,\n",
    "):\n",
    "    stopwords = set(SPACY_STOPWORDS)\n",
    "\n",
    "    def preprocess(text: str) -> str:\n",
    "        if text is None:\n",
    "            return \"\"\n",
    "        x = text.lower()\n",
    "        # quitar urls y menciones\n",
    "        x = URL_RE.sub(\" \", x)\n",
    "        x = MENTION_RE.sub(\" \", x)\n",
    "        # remover símbolo # pero conservar la palabra\n",
    "        x = HASHTAG_RE.sub(\"\", x)\n",
    "\n",
    "        # emojis\n",
    "        if handle_emojis == \"demojize\":\n",
    "            x = demojize_text(x)\n",
    "        elif handle_emojis == \"remove\":\n",
    "            x = remove_emojis(x)\n",
    "        # normalizar espacios\n",
    "        x = MULTI_SPACE_RE.sub(\" \", x).strip()\n",
    "\n",
    "        # uso spaCy para tokenizar/lematizar/stopwords/punct\n",
    "        if nlp is None:\n",
    "            # fallback simple tokenization\n",
    "            toks = x.split()\n",
    "            toks_proc = []\n",
    "            for t in toks:\n",
    "                if normalize_elong:\n",
    "                    t = normalize_elongation_token(t)\n",
    "                if drop_punct:\n",
    "                    t = PUNCT_RE.sub(\"\", t)\n",
    "                if drop_stopwords and t in stopwords:\n",
    "                    continue\n",
    "                toks_proc.append(t)\n",
    "            return \" \".join(toks_proc)\n",
    "\n",
    "        doc = nlp(x)\n",
    "        out_tokens = []\n",
    "        for tok in doc:\n",
    "            txt = tok.text\n",
    "            if normalize_elong:\n",
    "                txt = normalize_elongation_token(txt)\n",
    "            if drop_punct and tok.is_punct:\n",
    "                continue\n",
    "            if drop_stopwords and tok.text in stopwords:\n",
    "                continue\n",
    "            if lemmatize:\n",
    "                lemma = tok.lemma_.strip()\n",
    "                if lemma == \"-PRON-\":\n",
    "                    lemma = tok.text\n",
    "                if lemma != \"\":\n",
    "                    out_tokens.append(lemma)\n",
    "            else:\n",
    "                out_tokens.append(txt)\n",
    "        return \" \".join(out_tokens)\n",
    "\n",
    "    return preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c04f66df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810369</td>\n",
       "      <td>Mon Apr 06 22:19:45 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>_TheSpecialOne_</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810672</td>\n",
       "      <td>Mon Apr 06 22:19:49 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>scotthamilton</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1467810917</td>\n",
       "      <td>Mon Apr 06 22:19:53 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>mattycus</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811184</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>ElleCTF</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1467811193</td>\n",
       "      <td>Mon Apr 06 22:19:57 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Karoli</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag  \\\n",
       "0       0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
       "1       0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
       "2       0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
       "3       0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "4       0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
       "\n",
       "              user                                               text  \n",
       "0  _TheSpecialOne_  @switchfoot http://twitpic.com/2y1zl - Awww, t...  \n",
       "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
       "2         mattycus  @Kenichan I dived many times for the ball. Man...  \n",
       "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
       "4           Karoli  @nationwideclass no, it's not behaving at all....  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"training.1600000.processed.noemoticon.csv\", \n",
    "                 encoding=\"latin-1\", \n",
    "                 names=[\"target\", \"ids\", \"date\", \"flag\", \"user\", \"text\"])\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adf0c633",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_20724\\2477910676.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sampled = df.groupby('target', group_keys=False).apply(lambda x: x.sample(n=20000, random_state=SEED)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>text_preproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1974671194</td>\n",
       "      <td>Sat May 30 13:36:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>simba98</td>\n",
       "      <td>@xnausikaax oh no! where did u order from? tha...</td>\n",
       "      <td>oh u order horrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1997882236</td>\n",
       "      <td>Mon Jun 01 17:37:11 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Seve76</td>\n",
       "      <td>A great hard training weekend is over.  a coup...</td>\n",
       "      <td>great hard training weekend couple day rest le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2177756662</td>\n",
       "      <td>Mon Jun 15 06:39:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>x__claireyy__x</td>\n",
       "      <td>Right, off to work  Only 5 hours to go until I...</td>\n",
       "      <td>right work 5 hour free xd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2216838047</td>\n",
       "      <td>Wed Jun 17 20:02:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Balasi</td>\n",
       "      <td>I am craving for japanese food</td>\n",
       "      <td>crave japanese food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1880666283</td>\n",
       "      <td>Fri May 22 02:03:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>djrickdawson</td>\n",
       "      <td>Jean Michel Jarre concert tomorrow  gotta work...</td>\n",
       "      <td>jean michel jarre concert tomorrow get to work...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag            user  \\\n",
       "0       0  1974671194  Sat May 30 13:36:31 PDT 2009  NO_QUERY         simba98   \n",
       "1       0  1997882236  Mon Jun 01 17:37:11 PDT 2009  NO_QUERY          Seve76   \n",
       "2       0  2177756662  Mon Jun 15 06:39:05 PDT 2009  NO_QUERY  x__claireyy__x   \n",
       "3       0  2216838047  Wed Jun 17 20:02:12 PDT 2009  NO_QUERY          Balasi   \n",
       "4       0  1880666283  Fri May 22 02:03:31 PDT 2009  NO_QUERY    djrickdawson   \n",
       "\n",
       "                                                text  \\\n",
       "0  @xnausikaax oh no! where did u order from? tha...   \n",
       "1  A great hard training weekend is over.  a coup...   \n",
       "2  Right, off to work  Only 5 hours to go until I...   \n",
       "3                    I am craving for japanese food    \n",
       "4  Jean Michel Jarre concert tomorrow  gotta work...   \n",
       "\n",
       "                                        text_preproc  \n",
       "0                                oh u order horrible  \n",
       "1  great hard training weekend couple day rest le...  \n",
       "2                          right work 5 hour free xd  \n",
       "3                                crave japanese food  \n",
       "4  jean michel jarre concert tomorrow get to work...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersample: 20000 samples per target class\n",
    "df_sampled = df.groupby('target', group_keys=False).apply(lambda x: x.sample(n=20000, random_state=SEED)).reset_index(drop=True)\n",
    "\n",
    "# Preprocesamiento: usando preprocess_factory con spaCy\n",
    "nlp = spacy.load(SPACY_MODEL, disable=[\"parser\", \"ner\"])\n",
    "preprocess = preprocess_factory(\n",
    "    nlp=nlp,\n",
    "    lemmatize=True,\n",
    "    drop_stopwords=True,\n",
    "    handle_emojis=\"demojize\",\n",
    "    drop_punct=True,\n",
    "    normalize_elong=True\n",
    ")\n",
    "\n",
    "df_sampled['text_preproc'] = df_sampled['text'].apply(preprocess)\n",
    "df_sampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1ed1739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_20724\\1923147559.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sampled_2 = df.groupby('target', group_keys=False).apply(lambda x: x.sample(n=20000, random_state=SEED)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>text_preproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1974671194</td>\n",
       "      <td>Sat May 30 13:36:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>simba98</td>\n",
       "      <td>@xnausikaax oh no! where did u order from? tha...</td>\n",
       "      <td>oh u order horrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1997882236</td>\n",
       "      <td>Mon Jun 01 17:37:11 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Seve76</td>\n",
       "      <td>A great hard training weekend is over.  a coup...</td>\n",
       "      <td>great hard training weekend couple days rest l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2177756662</td>\n",
       "      <td>Mon Jun 15 06:39:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>x__claireyy__x</td>\n",
       "      <td>Right, off to work  Only 5 hours to go until I...</td>\n",
       "      <td>right work 5 hours free xd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2216838047</td>\n",
       "      <td>Wed Jun 17 20:02:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Balasi</td>\n",
       "      <td>I am craving for japanese food</td>\n",
       "      <td>craving japanese food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1880666283</td>\n",
       "      <td>Fri May 22 02:03:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>djrickdawson</td>\n",
       "      <td>Jean Michel Jarre concert tomorrow  gotta work...</td>\n",
       "      <td>jean michel jarre concert tomorrow got ta work...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag            user  \\\n",
       "0       0  1974671194  Sat May 30 13:36:31 PDT 2009  NO_QUERY         simba98   \n",
       "1       0  1997882236  Mon Jun 01 17:37:11 PDT 2009  NO_QUERY          Seve76   \n",
       "2       0  2177756662  Mon Jun 15 06:39:05 PDT 2009  NO_QUERY  x__claireyy__x   \n",
       "3       0  2216838047  Wed Jun 17 20:02:12 PDT 2009  NO_QUERY          Balasi   \n",
       "4       0  1880666283  Fri May 22 02:03:31 PDT 2009  NO_QUERY    djrickdawson   \n",
       "\n",
       "                                                text  \\\n",
       "0  @xnausikaax oh no! where did u order from? tha...   \n",
       "1  A great hard training weekend is over.  a coup...   \n",
       "2  Right, off to work  Only 5 hours to go until I...   \n",
       "3                    I am craving for japanese food    \n",
       "4  Jean Michel Jarre concert tomorrow  gotta work...   \n",
       "\n",
       "                                        text_preproc  \n",
       "0                                oh u order horrible  \n",
       "1  great hard training weekend couple days rest l...  \n",
       "2                         right work 5 hours free xd  \n",
       "3                              craving japanese food  \n",
       "4  jean michel jarre concert tomorrow got ta work...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersample: 20000 samples per target class\n",
    "df_sampled_2 = df.groupby('target', group_keys=False).apply(lambda x: x.sample(n=20000, random_state=SEED)).reset_index(drop=True)\n",
    "\n",
    "# Preprocesamiento: usando preprocess_factory con spaCy\n",
    "nlp = spacy.load(SPACY_MODEL, disable=[\"parser\", \"ner\"])\n",
    "preprocess = preprocess_factory(\n",
    "    nlp=nlp,\n",
    "    lemmatize=False,\n",
    "    drop_stopwords=True,\n",
    "    handle_emojis=\"demojize\",\n",
    "    drop_punct=True,\n",
    "    normalize_elong=True\n",
    ")\n",
    "\n",
    "df_sampled_2['text_preproc'] = df_sampled_2['text'].apply(preprocess)\n",
    "df_sampled_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3c36cfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_20724\\2458631395.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sampled_3 = df.groupby('target', group_keys=False).apply(lambda x: x.sample(n=20000, random_state=SEED)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>text_preproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1974671194</td>\n",
       "      <td>Sat May 30 13:36:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>simba98</td>\n",
       "      <td>@xnausikaax oh no! where did u order from? tha...</td>\n",
       "      <td>oh no where did u order from that 's horrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1997882236</td>\n",
       "      <td>Mon Jun 01 17:37:11 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Seve76</td>\n",
       "      <td>A great hard training weekend is over.  a coup...</td>\n",
       "      <td>a great hard training weekend is over a couple...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2177756662</td>\n",
       "      <td>Mon Jun 15 06:39:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>x__claireyy__x</td>\n",
       "      <td>Right, off to work  Only 5 hours to go until I...</td>\n",
       "      <td>right off to work only 5 hours to go until i '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2216838047</td>\n",
       "      <td>Wed Jun 17 20:02:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Balasi</td>\n",
       "      <td>I am craving for japanese food</td>\n",
       "      <td>i am craving for japanese food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1880666283</td>\n",
       "      <td>Fri May 22 02:03:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>djrickdawson</td>\n",
       "      <td>Jean Michel Jarre concert tomorrow  gotta work...</td>\n",
       "      <td>jean michel jarre concert tomorrow got ta work...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag            user  \\\n",
       "0       0  1974671194  Sat May 30 13:36:31 PDT 2009  NO_QUERY         simba98   \n",
       "1       0  1997882236  Mon Jun 01 17:37:11 PDT 2009  NO_QUERY          Seve76   \n",
       "2       0  2177756662  Mon Jun 15 06:39:05 PDT 2009  NO_QUERY  x__claireyy__x   \n",
       "3       0  2216838047  Wed Jun 17 20:02:12 PDT 2009  NO_QUERY          Balasi   \n",
       "4       0  1880666283  Fri May 22 02:03:31 PDT 2009  NO_QUERY    djrickdawson   \n",
       "\n",
       "                                                text  \\\n",
       "0  @xnausikaax oh no! where did u order from? tha...   \n",
       "1  A great hard training weekend is over.  a coup...   \n",
       "2  Right, off to work  Only 5 hours to go until I...   \n",
       "3                    I am craving for japanese food    \n",
       "4  Jean Michel Jarre concert tomorrow  gotta work...   \n",
       "\n",
       "                                        text_preproc  \n",
       "0      oh no where did u order from that 's horrible  \n",
       "1  a great hard training weekend is over a couple...  \n",
       "2  right off to work only 5 hours to go until i '...  \n",
       "3                     i am craving for japanese food  \n",
       "4  jean michel jarre concert tomorrow got ta work...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersample: 20000 samples per target class\n",
    "df_sampled_3 = df.groupby('target', group_keys=False).apply(lambda x: x.sample(n=20000, random_state=SEED)).reset_index(drop=True)\n",
    "\n",
    "# Preprocesamiento: usando preprocess_factory con spaCy\n",
    "nlp = spacy.load(SPACY_MODEL, disable=[\"parser\", \"ner\"])\n",
    "preprocess = preprocess_factory(\n",
    "    nlp=nlp,\n",
    "    lemmatize=False,\n",
    "    drop_stopwords=False,\n",
    "    handle_emojis=\"demojize\",\n",
    "    drop_punct=True,\n",
    "    normalize_elong=True\n",
    ")\n",
    "\n",
    "df_sampled_3['text_preproc'] = df_sampled_3['text'].apply(preprocess)\n",
    "df_sampled_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31955c44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_20724\\457044971.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sampled_4 = df.groupby('target', group_keys=False).apply(lambda x: x.sample(n=20000, random_state=SEED)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>text_preproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1974671194</td>\n",
       "      <td>Sat May 30 13:36:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>simba98</td>\n",
       "      <td>@xnausikaax oh no! where did u order from? tha...</td>\n",
       "      <td>oh no ! where do u order from ? that be horrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1997882236</td>\n",
       "      <td>Mon Jun 01 17:37:11 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Seve76</td>\n",
       "      <td>A great hard training weekend is over.  a coup...</td>\n",
       "      <td>a great hard training weekend be over . a coup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2177756662</td>\n",
       "      <td>Mon Jun 15 06:39:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>x__claireyy__x</td>\n",
       "      <td>Right, off to work  Only 5 hours to go until I...</td>\n",
       "      <td>right , off to work only 5 hour to go until I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2216838047</td>\n",
       "      <td>Wed Jun 17 20:02:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Balasi</td>\n",
       "      <td>I am craving for japanese food</td>\n",
       "      <td>I be crave for japanese food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1880666283</td>\n",
       "      <td>Fri May 22 02:03:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>djrickdawson</td>\n",
       "      <td>Jean Michel Jarre concert tomorrow  gotta work...</td>\n",
       "      <td>jean michel jarre concert tomorrow get to work...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag            user  \\\n",
       "0       0  1974671194  Sat May 30 13:36:31 PDT 2009  NO_QUERY         simba98   \n",
       "1       0  1997882236  Mon Jun 01 17:37:11 PDT 2009  NO_QUERY          Seve76   \n",
       "2       0  2177756662  Mon Jun 15 06:39:05 PDT 2009  NO_QUERY  x__claireyy__x   \n",
       "3       0  2216838047  Wed Jun 17 20:02:12 PDT 2009  NO_QUERY          Balasi   \n",
       "4       0  1880666283  Fri May 22 02:03:31 PDT 2009  NO_QUERY    djrickdawson   \n",
       "\n",
       "                                                text  \\\n",
       "0  @xnausikaax oh no! where did u order from? tha...   \n",
       "1  A great hard training weekend is over.  a coup...   \n",
       "2  Right, off to work  Only 5 hours to go until I...   \n",
       "3                    I am craving for japanese food    \n",
       "4  Jean Michel Jarre concert tomorrow  gotta work...   \n",
       "\n",
       "                                        text_preproc  \n",
       "0   oh no ! where do u order from ? that be horrible  \n",
       "1  a great hard training weekend be over . a coup...  \n",
       "2  right , off to work only 5 hour to go until I ...  \n",
       "3                       I be crave for japanese food  \n",
       "4  jean michel jarre concert tomorrow get to work...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersample: 20000 samples per target class\n",
    "df_sampled_4 = df.groupby('target', group_keys=False).apply(lambda x: x.sample(n=20000, random_state=SEED)).reset_index(drop=True)\n",
    "\n",
    "# Preprocesamiento: usando preprocess_factory con spaCy\n",
    "nlp = spacy.load(SPACY_MODEL, disable=[\"parser\", \"ner\"])\n",
    "preprocess = preprocess_factory(\n",
    "    nlp=nlp,\n",
    "    lemmatize=True,\n",
    "    drop_stopwords=False,\n",
    "    handle_emojis=\"remove\",\n",
    "    drop_punct=False,\n",
    "    normalize_elong=True\n",
    ")\n",
    "\n",
    "df_sampled_4['text_preproc'] = df_sampled_4['text'].apply(preprocess)\n",
    "df_sampled_4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "563bfb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\LENOVO\\AppData\\Local\\Temp\\ipykernel_20724\\1658939892.py:2: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_sampled_5 = df.groupby('target', group_keys=False).apply(lambda x: x.sample(n=20000, random_state=SEED)).reset_index(drop=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>ids</th>\n",
       "      <th>date</th>\n",
       "      <th>flag</th>\n",
       "      <th>user</th>\n",
       "      <th>text</th>\n",
       "      <th>text_preproc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1974671194</td>\n",
       "      <td>Sat May 30 13:36:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>simba98</td>\n",
       "      <td>@xnausikaax oh no! where did u order from? tha...</td>\n",
       "      <td>oh no ! where do u order from ? that be horrible</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1997882236</td>\n",
       "      <td>Mon Jun 01 17:37:11 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Seve76</td>\n",
       "      <td>A great hard training weekend is over.  a coup...</td>\n",
       "      <td>a great hard training weekend be over . a coup...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2177756662</td>\n",
       "      <td>Mon Jun 15 06:39:05 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>x__claireyy__x</td>\n",
       "      <td>Right, off to work  Only 5 hours to go until I...</td>\n",
       "      <td>right , off to work only 5 hour to go until I ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>2216838047</td>\n",
       "      <td>Wed Jun 17 20:02:12 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>Balasi</td>\n",
       "      <td>I am craving for japanese food</td>\n",
       "      <td>I be crave for japanese food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1880666283</td>\n",
       "      <td>Fri May 22 02:03:31 PDT 2009</td>\n",
       "      <td>NO_QUERY</td>\n",
       "      <td>djrickdawson</td>\n",
       "      <td>Jean Michel Jarre concert tomorrow  gotta work...</td>\n",
       "      <td>jean michel jarre concert tomorrow get to work...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target         ids                          date      flag            user  \\\n",
       "0       0  1974671194  Sat May 30 13:36:31 PDT 2009  NO_QUERY         simba98   \n",
       "1       0  1997882236  Mon Jun 01 17:37:11 PDT 2009  NO_QUERY          Seve76   \n",
       "2       0  2177756662  Mon Jun 15 06:39:05 PDT 2009  NO_QUERY  x__claireyy__x   \n",
       "3       0  2216838047  Wed Jun 17 20:02:12 PDT 2009  NO_QUERY          Balasi   \n",
       "4       0  1880666283  Fri May 22 02:03:31 PDT 2009  NO_QUERY    djrickdawson   \n",
       "\n",
       "                                                text  \\\n",
       "0  @xnausikaax oh no! where did u order from? tha...   \n",
       "1  A great hard training weekend is over.  a coup...   \n",
       "2  Right, off to work  Only 5 hours to go until I...   \n",
       "3                    I am craving for japanese food    \n",
       "4  Jean Michel Jarre concert tomorrow  gotta work...   \n",
       "\n",
       "                                        text_preproc  \n",
       "0   oh no ! where do u order from ? that be horrible  \n",
       "1  a great hard training weekend be over . a coup...  \n",
       "2  right , off to work only 5 hour to go until I ...  \n",
       "3                       I be crave for japanese food  \n",
       "4  jean michel jarre concert tomorrow get to work...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Undersample: 20000 samples per target class\n",
    "df_sampled_5 = df.groupby('target', group_keys=False).apply(lambda x: x.sample(n=20000, random_state=SEED)).reset_index(drop=True)\n",
    "\n",
    "# Preprocesamiento: usando preprocess_factory con spaCy\n",
    "nlp = spacy.load(SPACY_MODEL, disable=[\"parser\", \"ner\"])\n",
    "preprocess = preprocess_factory(\n",
    "    nlp=nlp,\n",
    "    lemmatize=True,\n",
    "    drop_stopwords=False,\n",
    "    handle_emojis=\"demojize\",\n",
    "    drop_punct=False,\n",
    "    normalize_elong=False\n",
    ")\n",
    "\n",
    "df_sampled_5['text_preproc'] = df_sampled_5['text'].apply(preprocess)\n",
    "df_sampled_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b924df9",
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Unigram TF-IDF\n",
    "tfidf_uni = TfidfVectorizer()\n",
    "X_uni_1 = tfidf_uni.fit_transform(df_sampled['text_preproc'])\n",
    "X_uni_2 = tfidf_uni.fit_transform(df_sampled_2['text_preproc'])\n",
    "X_uni_3 = tfidf_uni.fit_transform(df_sampled_3['text_preproc'])\n",
    "X_uni_4 = tfidf_uni.fit_transform(df_sampled_4['text_preproc'])\n",
    "X_uni_5 = tfidf_uni.fit_transform(df_sampled_5['text_preproc'])\n",
    "\n",
    "# Bigram TF-IDF\n",
    "tfidf_bi = TfidfVectorizer(ngram_range=(2, 2))\n",
    "X_bi_1 = tfidf_bi.fit_transform(df_sampled['text_preproc'])\n",
    "X_bi_2 = tfidf_bi.fit_transform(df_sampled_2['text_preproc'])\n",
    "X_bi_3 = tfidf_bi.fit_transform(df_sampled_3['text_preproc'])\n",
    "X_bi_4 = tfidf_bi.fit_transform(df_sampled_4['text_preproc'])\n",
    "X_bi_5 = tfidf_bi.fit_transform(df_sampled_5['text_preproc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0b0506c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "def evaluar_datasets(datasets, ngram_range=(1,1), prueba=\"Unigrama\"):\n",
    "    resultados = []\n",
    "    \n",
    "    for i, df in enumerate(datasets, start=1):\n",
    "        X = df[\"text_preproc\"]\n",
    "        y = df[\"target\"]\n",
    "\n",
    "        # Vectorización TF-IDF\n",
    "        vectorizer = TfidfVectorizer(max_features=5000, ngram_range=ngram_range)\n",
    "        X_tfidf = vectorizer.fit_transform(X)\n",
    "\n",
    "        # División 80/10/10 estratificada\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "            X_tfidf, y, test_size=0.2, stratify=y, random_state=42\n",
    "        )\n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "            X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42\n",
    "        )\n",
    "\n",
    "        # Entrenamiento con regresión logística\n",
    "        model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        # Evaluación en test\n",
    "        y_pred = model.predict(X_test)\n",
    "        f1 = f1_score(y_test, y_pred, average=\"weighted\")\n",
    "\n",
    "        resultados.append((f\"Modelo {i}\", f1))\n",
    "    \n",
    "    print(f\"\\nResultados {prueba}:\")\n",
    "    for modelo, score in resultados:\n",
    "        print(f\"{modelo}: F1-score = {score:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "de92b0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Resultados TF-IDF Unigrama:\n",
      "Modelo 1: F1-score = 0.7379\n",
      "Modelo 2: F1-score = 0.7404\n",
      "Modelo 3: F1-score = 0.7727\n",
      "Modelo 4: F1-score = 0.7742\n",
      "Modelo 5: F1-score = 0.7730\n",
      "\n",
      "Resultados TF-IDF Bigrama:\n",
      "Modelo 1: F1-score = 0.7399\n",
      "Modelo 2: F1-score = 0.7411\n",
      "Modelo 3: F1-score = 0.7722\n",
      "Modelo 4: F1-score = 0.7765\n",
      "Modelo 5: F1-score = 0.7770\n"
     ]
    }
   ],
   "source": [
    "# Lista con los 5 datasets\n",
    "datasets = [df_sampled, df_sampled_2, df_sampled_3, df_sampled_4, df_sampled_5]\n",
    "\n",
    "# Prueba 1: TF-IDF Unigrama\n",
    "evaluar_datasets(datasets, ngram_range=(1,1), prueba=\"TF-IDF Unigrama\")\n",
    "\n",
    "# Prueba 2: TF-IDF Bigrama\n",
    "evaluar_datasets(datasets, ngram_range=(1,2), prueba=\"TF-IDF Bigrama\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d1dfcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
